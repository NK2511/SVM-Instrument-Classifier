{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 0.0329 seconds, for 25 components\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Sound_Violin       0.96      0.96      0.96       131\n",
      " Sound_Piano       0.89      0.77      0.83        53\n",
      "Sound_Guitar       0.91      0.96      0.93       186\n",
      "  Sound_Drum       0.99      0.99      0.99       281\n",
      "     Unknown       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.95       657\n",
      "   macro avg       0.95      0.77      0.80       657\n",
      "weighted avg       0.95      0.95      0.95       657\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "              Sound_Violin  Sound_Piano  Sound_Guitar  Sound_Drum  Unknown\n",
      "Sound_Violin           278            2             0           1        0\n",
      "Sound_Piano              2          179             5           0        0\n",
      "Sound_Guitar             0           12            41           0        0\n",
      "Sound_Drum               1            4             0         126        0\n",
      "Unknown                  1            0             0           4        1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['expca_model.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler  # Import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import joblib\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Step 1: Load the Data\n",
    "features_df = pd.read_csv('Extended_features_extracted.csv')\n",
    "\n",
    "# Step 2: Prepare the Data\n",
    "featurecol = features_df.columns[:-2]\n",
    "X = features_df[featurecol].values\n",
    "y = features_df['sound_type'].values \n",
    "\n",
    "# Step 3: Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Apply PCA for Dimensionality Reduction\n",
    "n_components = 25  # Adjust this based on your needs (e.g., 10, 15, or 20)\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Start time measurement\n",
    "start_time = time.time()  # Record start time\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# End time measurement\n",
    "end_time = time.time()  # Record end time\n",
    "\n",
    "# Calculate PCA execution time\n",
    "exec_time = end_time - start_time\n",
    "print(f\"Execution Time: {exec_time:.4f} seconds, for {n_components} components\")  # Print execution time\n",
    "\n",
    "# Step 5: Train an SVM Classifier on the PCA-transformed data\n",
    "classifier = SVC(kernel='rbf', C=100, gamma='auto', random_state=42,probability=True)\n",
    "classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "# Step 6: Evaluate the Classifier\n",
    "y_pred = classifier.predict(X_test_pca)\n",
    "\n",
    "labels = [\"Sound_Violin\", \"Sound_Piano\", \"Sound_Guitar\", \"Sound_Drum\", \"Unknown\"]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_df)\n",
    "joblib.dump(classifier, 'exsvm_model.pkl') \n",
    "joblib.dump(scaler, 'exscaler.pkl')  # Save the scaler\n",
    "joblib.dump(pca, 'expca_model.pkl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start playing your instrument...\n",
      "Recording continuously...\n",
      "Detected Instrument: Sound_Drum (Confidence: 95.56%)\n",
      "Detected Instrument: Sound_Drum (Confidence: 97.63%)\n",
      "Detected Instrument: Sound_Drum (Confidence: 98.70%)\n",
      "Detected Instrument: Sound_Drum (Confidence: 97.20%)\n",
      "Detected Instrument: Sound_Drum (Confidence: 97.92%)\n",
      "Detected Instrument: Sound_Drum (Confidence: 75.99%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 58\u001b[0m\n\u001b[0;32m     54\u001b[0m audio_generator \u001b[38;5;241m=\u001b[39m record_audio_continuous()\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart playing your instrument...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m audio \u001b[38;5;129;01min\u001b[39;00m audio_generator:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_sound_present(audio):\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;66;03m# Extract features and preprocess\u001b[39;00m\n\u001b[0;32m     61\u001b[0m         features \u001b[38;5;241m=\u001b[39m extract_features(audio)\n",
      "Cell \u001b[1;32mIn[6], line 50\u001b[0m, in \u001b[0;36mrecord_audio_continuous\u001b[1;34m(sample_rate, chunk_duration)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(\u001b[38;5;28mint\u001b[39m(chunk_duration \u001b[38;5;241m*\u001b[39m sample_rate), samplerate\u001b[38;5;241m=\u001b[39msample_rate, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m     \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Wait for the chunk to be recorded\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sounddevice.py:395\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(ignore_errors)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m \n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[1;32m--> 395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sounddevice.py:2601\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[1;34m(self, ignore_errors)\u001b[0m\n\u001b[0;32m   2595\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[0;32m   2596\u001b[0m \n\u001b[0;32m   2597\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[0;32m   2598\u001b[0m \n\u001b[0;32m   2599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2600\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2601\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2602\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import librosa\n",
    "import joblib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# Load your trained SVM model, scaler, and PCA model\n",
    "model = joblib.load('exsvm_model.pkl')\n",
    "scaler = joblib.load('exscaler.pkl')\n",
    "pca = joblib.load('expca_model.pkl')\n",
    "\n",
    "# Amplitude threshold for detecting sound (adjust based on your environment)\n",
    "AMPLITUDE_THRESHOLD = 0.00 # Experiment with this value to filter out quiet sounds\n",
    "\n",
    "# Function to check if the audio amplitude exceeds the threshold\n",
    "def is_sound_present(audio):\n",
    "    return np.max(np.abs(audio)) > AMPLITUDE_THRESHOLD\n",
    "\n",
    "# Function to extract features from audio\n",
    "def extract_features(audio, sample_rate=44100):\n",
    "    # MFCCs\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "    # Chroma\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "    # Spectral Contrast\n",
    "    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "    # Zero Crossing Rate\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=audio).T, axis=0)\n",
    "    # Root Mean Square Energy (RMSE)\n",
    "    rmse = np.mean(librosa.feature.rms(y=audio).T, axis=0)\n",
    "    # Harmonic-to-Noise Ratio (HNR)\n",
    "    hnr = np.mean(librosa.effects.hpss(audio)[1])\n",
    "    # Spectral Centroid\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "    # Spectral Bandwidth\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=audio, sr=sample_rate).T, axis=0)\n",
    "    # Spectral Flatness\n",
    "    spectral_flatness = np.mean(librosa.feature.spectral_flatness(y=audio).T, axis=0)\n",
    "    # Spectral Rolloff\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, roll_percent=0.85).T, axis=0)\n",
    "    stft = np.abs(librosa.stft(audio))\n",
    "    spectral_flux = np.mean(np.sqrt(np.sum(np.diff(stft, axis=1) ** 2, axis=0)))\n",
    "    return np.hstack((mfccs, chroma, spectral_contrast, zcr, rmse, [hnr], spectral_centroid, spectral_bandwidth, spectral_flatness, spectral_rolloff, spectral_flux))\n",
    "\n",
    "def record_audio_continuous(sample_rate=44100, chunk_duration=3):\n",
    "    print(\"Recording continuously...\")\n",
    "    while True:\n",
    "        chunk = sd.rec(int(chunk_duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')\n",
    "        sd.wait()  # Wait for the chunk to be recorded\n",
    "        yield chunk.flatten()\n",
    "\n",
    "# Continuous recording and classification\n",
    "audio_generator = record_audio_continuous()\n",
    "\n",
    "print(\"Start playing your instrument...\")\n",
    "\n",
    "for audio in audio_generator:\n",
    "    if is_sound_present(audio):\n",
    "        # Extract features and preprocess\n",
    "        features = extract_features(audio)\n",
    "        features_scaled = scaler.transform([features])\n",
    "        features_pca = pca.transform(features_scaled)\n",
    "\n",
    "        # Make a prediction\n",
    "        prediction = model.predict(features_pca)\n",
    "        instrument = prediction[0]\n",
    "        \n",
    "        # Check the probability/confidence of the prediction\n",
    "        probabilities = model.predict_proba(features_pca)\n",
    "        confidence = np.max(probabilities)\n",
    "\n",
    "        if confidence > 0.7:  # Adjust the confidence threshold as needed\n",
    "            print(f\"Detected Instrument: {instrument} (Confidence: {confidence * 100:.2f}%)\")\n",
    "        else:\n",
    "            print(\"Ambient noise detected (Confidence too low)\")\n",
    "    else:\n",
    "        print(\"No music detected\")\n",
    "\n",
    "    time.sleep(1)  # Pause before the next prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
